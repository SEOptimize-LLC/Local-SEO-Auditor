---
name: review-audit
description: Comprehensive review signals audit with generation strategy and competitor benchmarking
version: 1.0.0
tags: [local-seo, reviews, reputation, gbp, audit]
related: [gbp-audit, local-competitor-analysis, local-citation-audit, local-seo-reporting]
---

# Phase 3: Review Signals Audit (FLAGSHIP)

Reviews are the single most actionable ranking lever for local businesses. This skill
provides a complete framework for auditing review health, benchmarking against competitors,
building a review generation engine, and crafting response strategies that compound
ranking gains over time.

---

## When to Use This Skill

- When performing a full Local SEO Audit (Phase 3 of the standard audit sequence)
- When a client's Map Pack rankings have stalled or declined
- When a competitor is outranking the client despite weaker on-page signals
- When a client has no formal review generation or response process
- When review velocity has dropped and rankings are slipping
- When preparing a 90-day local SEO action plan
- When onboarding a new local SEO client and establishing baselines

### Why Reviews Matter More Than Ever

Reviews now account for **20% of Local Map Pack ranking factors** -- this has DOUBLED
from prior estimates based on 2025 Whitespark Local Search Ranking Factors data. For most
local businesses, reviews are the PRIMARY lever they can directly influence. Unlike
technical SEO or link building, every business can take immediate action on reviews.

---

## Channel Impact

| Channel    | Weight | Note                                                  |
|------------|--------|-------------------------------------------------------|
| Map Pack   | 20%    | Primary lever -- doubled importance in 2025 data      |
| Organic    | 15%    | Reviews influence CTR and trust signals in organic     |
| AI Search  | 16%    | AI engines cite review sentiment and volume in answers |

**Combined impact**: Review signals influence over 50% of local visibility when you
account for their cross-channel effects. No other single factor has this breadth of
influence across Map Pack, organic, and AI search simultaneously.

---

## Prerequisites

Before starting the Review Signals Audit, ensure you have:

1. **Discovery brief from Phase 1** -- business name, category, service area, target
   keywords, and competitive landscape overview
2. **GBP listing URL** -- the client's primary Google Business Profile listing
3. **Competitor GBP listings** -- minimum 3, ideally 5 direct competitors in the same
   service area and category
4. **Optional but highly valuable**:
   - GBP review export (available via Google Takeout or GBP manager)
   - Third-party review data from Yelp, Facebook, HomeAdvisor, BBB
   - Historical review tracking data from BrightLocal, Whitespark, or similar
   - Current review generation process documentation
   - Existing review response templates

---

## Assessment Framework

### 1. Review Volume Analysis

Review volume is the foundational metric. Without sufficient volume, all other review
signals are weakened.

**Key thresholds**:

| Volume Range | Classification    | Ranking Impact                                    |
|--------------|-------------------|---------------------------------------------------|
| 0-4 reviews  | Critical deficit  | Virtually invisible in Map Pack                   |
| 5-9 reviews  | Below minimum     | Marginal visibility, easily outranked             |
| 10-19 reviews| Minimum viable    | Significant ranking jump at 10-review threshold   |
| 20-49 reviews| Competitive base  | Average for local businesses (15-30 typical)      |
| 50-99 reviews| Strong position   | Above average, competitive in most markets        |
| 100+ reviews | Dominant position | Top-tier, hard for competitors to overcome         |

**Audit steps**:

1. Record current total Google review count from GBP listing
2. Check if the business has crossed the **10-review threshold** -- this is where
   a significant ranking jump occurs; businesses below 10 reviews are at a severe
   disadvantage
3. Calculate the **review gap**: if the top competitor has 150 reviews and the client
   has 45, that is a 105-review deficit that must be closed over time
4. Catalog reviews across ALL platforms:
   - Google Business Profile (primary)
   - Yelp
   - HomeAdvisor / Angie's List
   - Facebook Recommendations
   - Better Business Bureau (BBB)
   - Industry-specific platforms (Avvo for lawyers, Healthgrades for doctors,
     Houzz for home services, TripAdvisor for hospitality, etc.)
5. Calculate **total review footprint** across all platforms
6. Note any platforms where competitors have presence but client does not

**Volume gap analysis template**:

```
Client: [Business Name]
Google Reviews: [X]
Total Cross-Platform Reviews: [Y]

Top Competitor Reviews (Google):
- Competitor 1: [X] reviews
- Competitor 2: [X] reviews
- Competitor 3: [X] reviews
- Competitor 4: [X] reviews
- Competitor 5: [X] reviews

Average Competitor Reviews: [X]
Gap to Average: [X] reviews
Gap to Leader: [X] reviews
Estimated months to close gap (at 5-10/month): [X] months
```

---

### 2. Review Rating Analysis

Rating quality is the second pillar. A high volume of mediocre reviews can actually
harm rankings and conversion.

**Competitive thresholds**:

| Rating Range | Classification      | Impact                                       |
|--------------|---------------------|----------------------------------------------|
| Below 3.5    | Severe problem      | Active ranking suppression, conversion killer|
| 3.5-3.9      | Below competitive   | Disadvantaged in Map Pack filtering          |
| 4.0-4.4      | Minimum competitive | Visible but not preferred by algorithm       |
| 4.5-4.6      | Competitive         | Solid position, room for improvement         |
| 4.7-4.8      | Strong competitive  | Sweet spot for most markets                  |
| 4.9-5.0      | Premium position    | Maximum rating signal, may appear "too perfect"|

**Rating distribution analysis**:

Break down reviews by star rating to understand the distribution shape:

```
5-star: [X] reviews ([X]%)
4-star: [X] reviews ([X]%)
3-star: [X] reviews ([X]%)
2-star: [X] reviews ([X]%)
1-star: [X] reviews ([X]%)

Average: [X.X]
Median: [X]
Mode: [X]
```

**Key patterns to identify**:

- **Healthy distribution**: 70%+ 5-star, declining percentages downward
- **Polarized distribution**: Many 5-star AND many 1-star = service consistency issue
- **Middling distribution**: Heavy 3-4 star concentration = "fine but not remarkable"
- **Declining trend**: Average rating dropping over time = operational problem

**Rating trend analysis**: Plot the rolling 3-month average rating over the past 12
months. Look for:

- Improving trend (positive operational changes taking effect)
- Declining trend (service quality issues emerging)
- Stable trend (consistent but may need improvement)
- Volatile trend (inconsistent service delivery)

**The 0.1-point gap**: When comparing against competitors, a -0.1 rating gap matters
more when both businesses have high volume. A business with 200 reviews at 4.6 vs
a competitor with 180 reviews at 4.7 is at a meaningful disadvantage.

---

### 3. Review Velocity (NOW MORE IMPORTANT THAN VOLUME)

This is the single most underrated review metric. Google's algorithm increasingly
favors **consistent ongoing engagement** over historical accumulation.

**Critical insight**: 2 consistent reviews per month is MORE valuable than 20 reviews
arriving once per year. The algorithm interprets steady velocity as a signal of an
active, thriving business.

**Velocity benchmarks**:

| Monthly Velocity | Classification    | Signal to Algorithm                           |
|------------------|-------------------|-----------------------------------------------|
| 0 reviews/month  | Stalled           | Business may be inactive or declining          |
| 1 review/month   | Minimal           | Bare minimum activity signal                   |
| 2-4/month        | Healthy baseline  | Consistent engagement, adequate for most       |
| 5-9/month        | Strong growth     | Active business with engaged customer base     |
| 10+/month        | Aggressive growth | Dominant velocity, hard for competitors to match|

**How to measure velocity**:

1. Count reviews by month for the past 12 months
2. Calculate the rolling 3-month average
3. Identify any months with zero reviews (velocity gaps)
4. Compare velocity trend: accelerating, decelerating, or flat

**Velocity tracking template**:

```
Month         | Reviews | Cumulative | Rolling 3-Mo Avg
------------- | ------- | ---------- | ----------------
[Month -12]   | [X]     | [X]        | --
[Month -11]   | [X]     | [X]        | --
[Month -10]   | [X]     | [X]        | [X.X]
[Month -9]    | [X]     | [X]        | [X.X]
[Month -8]    | [X]     | [X]        | [X.X]
[Month -7]    | [X]     | [X]        | [X.X]
[Month -6]    | [X]     | [X]        | [X.X]
[Month -5]    | [X]     | [X]        | [X.X]
[Month -4]    | [X]     | [X]        | [X.X]
[Month -3]    | [X]     | [X]        | [X.X]
[Month -2]    | [X]     | [X]        | [X.X]
[Month -1]    | [X]     | [X]        | [X.X]
Current Month | [X]     | [X]        | [X.X]
```

**90-day velocity targets**:

- Aggressive: 20-30 new reviews over 90 days (approximately 7-10 per month)
- Moderate: 15-20 new reviews over 90 days (approximately 5-7 per month)
- Conservative: 10-15 new reviews over 90 days (approximately 3-5 per month)

---

### 4. Review Keywords and Content Quality

Reviews that contain specific service keywords and location names directly contribute
to ranking for those terms. This is one of the most powerful -- and most overlooked --
aspects of review strategy.

**Why review keywords matter**:

- A review mentioning "emergency drain cleaning" helps the business rank for that phrase
- Location mentions in reviews ("great service in Scottsdale") reinforce geographic
  relevance signals
- Negative keywords in reviews ("terrible plumbing work") can actively hurt rankings
  for those service terms

**Audit procedure**:

1. Export or manually compile all review text (Google reviews minimum)
2. Run keyword frequency analysis across all review text
3. Identify which service keywords appear naturally in reviews
4. Identify which target keywords are MISSING from reviews
5. Check for negative keyword patterns (complaint themes)
6. Compare keyword richness against competitor reviews

**Review keyword analysis -- Python code**:

```python
"""
Review Text Analyzer
Extracts keyword frequency, sentiment themes, and service mentions
from a collection of review texts.
"""

import re
from collections import Counter
from typing import List, Dict, Tuple


def clean_text(text: str) -> str:
    """Normalize review text for analysis."""
    text = text.lower().strip()
    text = re.sub(r'[^\w\s]', ' ', text)
    text = re.sub(r'\s+', ' ', text)
    return text


def extract_ngrams(text: str, n: int = 2) -> List[str]:
    """Extract n-grams from text for phrase analysis."""
    words = text.split()
    return [' '.join(words[i:i+n]) for i in range(len(words) - n + 1)]


# Common stop words to filter out
STOP_WORDS = {
    'the', 'a', 'an', 'is', 'was', 'were', 'are', 'been', 'be', 'have',
    'has', 'had', 'do', 'does', 'did', 'will', 'would', 'could', 'should',
    'may', 'might', 'can', 'shall', 'to', 'of', 'in', 'for', 'on', 'with',
    'at', 'by', 'from', 'as', 'into', 'through', 'during', 'before',
    'after', 'above', 'below', 'between', 'out', 'off', 'over', 'under',
    'again', 'further', 'then', 'once', 'here', 'there', 'when', 'where',
    'why', 'how', 'all', 'both', 'each', 'few', 'more', 'most', 'other',
    'some', 'such', 'no', 'nor', 'not', 'only', 'own', 'same', 'so',
    'than', 'too', 'very', 'just', 'because', 'and', 'but', 'or', 'if',
    'while', 'about', 'up', 'it', 'its', 'i', 'my', 'we', 'our', 'you',
    'your', 'they', 'their', 'them', 'he', 'she', 'him', 'her', 'this',
    'that', 'these', 'those', 'what', 'which', 'who', 'whom', 'me', 'us',
    'his', 'get', 'got', 'also', 'really', 'much', 'well', 'back',
    'even', 'still', 'way', 'take', 'come', 'go', 'make', 'like',
    'time', 'thing', 'right', 'know', 'went', 'came', 'made',
}


# Sentiment keyword lists for review analysis
POSITIVE_SIGNALS = [
    'excellent', 'amazing', 'outstanding', 'exceptional', 'fantastic',
    'professional', 'prompt', 'reliable', 'honest', 'fair', 'reasonable',
    'courteous', 'knowledgeable', 'efficient', 'thorough', 'friendly',
    'responsive', 'punctual', 'clean', 'respectful', 'trustworthy',
    'recommend', 'highly recommend', 'best', 'great', 'wonderful',
    'impressed', 'satisfied', 'happy', 'pleased', 'grateful',
    'above and beyond', 'top notch', 'first rate', 'five star',
]

NEGATIVE_SIGNALS = [
    'terrible', 'horrible', 'awful', 'worst', 'rude', 'unprofessional',
    'overcharged', 'overpriced', 'expensive', 'late', 'no show',
    'didn\'t show', 'never came', 'damaged', 'broke', 'incompetent',
    'dishonest', 'scam', 'ripoff', 'rip off', 'avoid', 'never again',
    'disappointed', 'frustrating', 'unresponsive', 'ignored',
    'poor quality', 'sloppy', 'careless', 'unreliable',
]


def analyze_reviews(
    reviews: List[Dict[str, str]],
    service_keywords: List[str],
    location_keywords: List[str],
) -> Dict:
    """
    Full review text analysis.

    Args:
        reviews: List of dicts with keys 'text', 'rating', 'date'
        service_keywords: Target service keywords to check for
        location_keywords: Target location/city names to check for

    Returns:
        Dict with analysis results
    """
    all_text = ' '.join(clean_text(r['text']) for r in reviews)
    words = [w for w in all_text.split() if w not in STOP_WORDS and len(w) > 2]

    # Single word frequency
    word_freq = Counter(words).most_common(50)

    # Bigram frequency (two-word phrases)
    bigrams = extract_ngrams(all_text, 2)
    bigram_freq = Counter(bigrams).most_common(30)

    # Trigram frequency (three-word phrases)
    trigrams = extract_ngrams(all_text, 3)
    trigram_freq = Counter(trigrams).most_common(20)

    # Service keyword presence
    service_mentions = {}
    for kw in service_keywords:
        count = all_text.count(kw.lower())
        service_mentions[kw] = {
            'count': count,
            'percentage': round(count / len(reviews) * 100, 1) if reviews else 0,
        }

    # Location keyword presence
    location_mentions = {}
    for loc in location_keywords:
        count = all_text.count(loc.lower())
        location_mentions[loc] = {
            'count': count,
            'percentage': round(count / len(reviews) * 100, 1) if reviews else 0,
        }

    # Sentiment analysis
    positive_count = sum(1 for sig in POSITIVE_SIGNALS if sig in all_text)
    negative_count = sum(1 for sig in NEGATIVE_SIGNALS if sig in all_text)

    positive_found = [sig for sig in POSITIVE_SIGNALS if sig in all_text]
    negative_found = [sig for sig in NEGATIVE_SIGNALS if sig in all_text]

    return {
        'total_reviews': len(reviews),
        'total_words': len(words),
        'avg_review_length': len(words) // len(reviews) if reviews else 0,
        'top_words': word_freq,
        'top_bigrams': bigram_freq,
        'top_trigrams': trigram_freq,
        'service_keyword_mentions': service_mentions,
        'location_keyword_mentions': location_mentions,
        'positive_signals_found': positive_found,
        'negative_signals_found': negative_found,
        'sentiment_ratio': round(
            positive_count / max(negative_count, 1), 2
        ),
    }


# --- Usage Example ---
if __name__ == '__main__':
    sample_reviews = [
        {
            'text': 'Excellent emergency drain cleaning service. They came out to '
                    'our Scottsdale home within an hour. Very professional.',
            'rating': '5',
            'date': '2025-01-15',
        },
        {
            'text': 'Good plumbing work but a bit pricey. The technician was '
                    'knowledgeable and fixed our water heater quickly.',
            'rating': '4',
            'date': '2025-01-10',
        },
    ]

    service_kws = [
        'drain cleaning', 'plumbing', 'water heater', 'emergency',
        'sewer', 'leak repair', 'pipe',
    ]
    location_kws = ['scottsdale', 'phoenix', 'tempe', 'mesa']

    results = analyze_reviews(sample_reviews, service_kws, location_kws)

    print("=== Review Text Analysis ===")
    print(f"Total reviews analyzed: {results['total_reviews']}")
    print(f"Average review length: {results['avg_review_length']} words")
    print(f"\nTop words: {results['top_words'][:10]}")
    print(f"\nService keyword mentions:")
    for kw, data in results['service_keyword_mentions'].items():
        print(f"  {kw}: {data['count']} mentions ({data['percentage']}% of reviews)")
    print(f"\nPositive signals: {results['positive_signals_found']}")
    print(f"Negative signals: {results['negative_signals_found']}")
    print(f"Sentiment ratio: {results['sentiment_ratio']}")
```

**Keyword gap identification**: After running the analysis, compare the keywords
found in reviews against the client's target keyword list. Any target keyword NOT
appearing in reviews represents a gap that the review generation strategy should address.

---

### 5. Review Diversity

Review diversity signals to Google that the business serves a broad area and has a
wide customer base, not just a few friends and family leaving reviews.

**Geographic spread**:

- Reviews from different neighborhoods, cities, and ZIP codes across the service area
  signal broad geographic relevance
- If all reviews come from a single neighborhood, Google may interpret this as a very
  limited service area
- Audit: check reviewer profiles for location indicators where available

**Reviewer profile quality**:

- Verified Local Guide reviewers carry significantly more weight than new accounts
- Reviewers with review history (50+ reviews on their profile) are weighted higher
- Single-review accounts are weighted lower and may trigger spam detection if they
  appear in clusters
- Red flag: multiple reviews from accounts with no other review history arriving in
  a short timeframe

**Platform diversity audit**:

| Platform       | Client Reviews | Comp 1 | Comp 2 | Comp 3 | Comp 4 | Comp 5 |
|----------------|---------------|--------|--------|--------|--------|--------|
| Google         | [X]           | [X]    | [X]    | [X]    | [X]    | [X]    |
| Yelp           | [X]           | [X]    | [X]    | [X]    | [X]    | [X]    |
| Facebook       | [X]           | [X]    | [X]    | [X]    | [X]    | [X]    |
| HomeAdvisor    | [X]           | [X]    | [X]    | [X]    | [X]    | [X]    |
| BBB            | [X]           | [X]    | [X]    | [X]    | [X]    | [X]    |
| Industry-Spec  | [X]           | [X]    | [X]    | [X]    | [X]    | [X]    |
| **Total**      | **[X]**       | **[X]**| **[X]**| **[X]**| **[X]**| **[X]**|

---

### 6. Review Recency

Google's algorithm applies a time-decay function to reviews. Recent reviews are
weighted substantially more than old ones.

**Recency weighting (approximate)**:

| Age of Review   | Relative Weight | Impact                                    |
|-----------------|-----------------|-------------------------------------------|
| Last 7 days     | 100%            | Maximum freshness signal                   |
| Last 30 days    | 85-90%          | Very high relevance                        |
| Last 90 days    | 60-75%          | Moderate relevance, still valuable         |
| 3-6 months      | 40-50%          | Declining relevance                        |
| 6-12 months     | 20-30%          | Low weight but still contributes to volume |
| 12+ months      | 10-15%          | Minimal ranking impact, social proof only  |

**Recency audit steps**:

1. Count reviews received in the last 7 days
2. Count reviews received in the last 30 days
3. Count reviews received in the last 90 days
4. Identify the date of the most recent review
5. Identify any gaps longer than 30 days with zero reviews in the past year
6. Calculate what percentage of total reviews came in the last 6 months

**Red flags**:

- No reviews in the last 30 days
- Most recent review is 60+ days old
- Longest gap between reviews exceeds 45 days
- Less than 20% of total reviews came in the last 6 months

---

### 7. Review Response Analysis

Owner responses to reviews are both a ranking signal and a conversion factor.
Businesses that respond to reviews see measurable improvements in both rankings
and future review generation.

**Impact data**:

- Businesses that respond to reviews see **+12% increase in review volume** (customers
  are more likely to leave a review when they see the owner engages)
- Consistent responses correlate with **+15% rating improvement** over 6 months
- Google confirms owner responses are a factor in local ranking

**Response audit metrics**:

| Metric                        | Target        | Client Score |
|-------------------------------|---------------|--------------|
| Overall response rate         | 100%          | [X]%         |
| Positive review response rate | 100%          | [X]%         |
| Negative review response rate | 100%          | [X]%         |
| Average response time         | < 24 hours    | [X] hours    |
| Response personalization      | High          | [Low/Med/Hi] |
| Keyword inclusion in responses| Consistent    | [Y/N]        |

**Response quality assessment criteria**:

- **Bad response**: "Thanks!" (generic, no value, no keywords)
- **Mediocre response**: "Thank you for your review, we appreciate your business."
  (slightly better but still templated and keyword-free)
- **Good response**: "Thank you for choosing [Business Name] for your [specific
  service mentioned in review]. We're glad our team could [reference specific
  outcome]. We look forward to helping you with any future [service category]
  needs in [location]."

**Review response templates**:

#### Template 1: Positive Review Response (5-star)

```
Thank you so much for the wonderful review, [Reviewer Name]! We're thrilled
that our [SERVICE MENTIONED] team was able to [SPECIFIC OUTCOME FROM REVIEW].
Providing [CORE VALUE - e.g., reliable, professional, prompt] [SERVICE CATEGORY]
to [CITY/AREA] homeowners is what drives us every day. If you ever need
[RELATED SERVICE 1] or [RELATED SERVICE 2] in the future, don't hesitate
to reach out. We truly appreciate your trust in [BUSINESS NAME]!
```

#### Template 2: Positive Review Response (4-star)

```
Thank you for the great feedback, [Reviewer Name]! We're glad you had a
positive experience with our [SERVICE MENTIONED] service. We noticed you
mentioned [ANY CONCERN OR LESS-THAN-PERFECT ASPECT], and we'd love to hear
more about how we can earn that fifth star next time. Our [SERVICE CATEGORY]
team in [CITY/AREA] is always working to improve. Feel free to reach out
directly at [PHONE/EMAIL] -- we value your input!
```

#### Template 3: Negative Review Response (1-3 star)

```
[Reviewer Name], thank you for taking the time to share your experience. We
sincerely apologize that our [SERVICE MENTIONED] did not meet your expectations.
This is not the standard we hold ourselves to at [BUSINESS NAME]. We take your
feedback very seriously and would like the opportunity to make this right.

Please contact [OWNER/MANAGER NAME] directly at [PHONE] or [EMAIL] so we can
discuss your concerns and find a resolution. Your satisfaction is our top
priority, and we want to ensure every [CITY/AREA] customer receives the
exceptional [SERVICE CATEGORY] they deserve.
```

#### Template 4: Suspected Fake/Spam Review Response

```
Thank you for your feedback. We take all reviews seriously, however we are
unable to locate a record of this interaction in our system. We serve
[CITY/AREA] with [SERVICE CATEGORY] and maintain detailed records of all
service calls.

If you did work with [BUSINESS NAME], please contact us directly at [PHONE]
with your service date and address so we can look into this further. We are
committed to resolving any legitimate concerns.
```

After posting the response, flag the review through Google's review flagging process
for further investigation.

---

## Review Generation Framework

### The Multi-Channel Collection System

A sustainable review generation engine uses multiple channels running simultaneously.
No single channel should carry 100% of the effort.

#### Channel 1: SMS/Text Request (HIGHEST CONVERSION -- Send 24 Hours Post-Job)

**Why it works**: Text messages have 98% open rates and customers are still engaged
with the experience within 24 hours of service.

**Template**:

```
Hi [FIRST NAME], thanks for choosing [BUSINESS NAME]! We'd love to hear about
your experience. It takes less than 60 seconds:
[SHORT_URL]
```

**Implementation**:

- Send exactly 24 hours after job completion (not immediately -- give them time
  to assess the work, but not so long they forget)
- Use a URL shortener (bit.ly, rebrandly) for a clean, non-intimidating link
- The link should go directly to the Google review form (not a landing page)
- Automate with platforms: Podium, Birdeye, GatherUp, NiceJob, or Grade.us
- Expected conversion rate: **10-20%** of recipients will leave a review
- Follow-up: If no review in 3 days, send ONE follow-up text (no more)

**Follow-up template**:

```
Hi [FIRST NAME], just a quick reminder -- your feedback helps us serve
[CITY/AREA] better! Leave a quick review here if you have a moment:
[SHORT_URL]
No worries if not. Thanks again for choosing [BUSINESS NAME]!
```

#### Channel 2: Email Request (Weekly Batch to Past Customers)

**Subject line templates** (test and rotate):

- "How did we do, [FIRST NAME]?"
- "[FIRST NAME], your opinion matters to us"
- "Quick favor? Share your [BUSINESS NAME] experience"
- "We'd love your feedback on our [SERVICE] work"

**Body template**:

```
Hi [FIRST NAME],

Thank you for choosing [BUSINESS NAME] for your recent [SERVICE TYPE].
We hope everything is working perfectly!

Your feedback helps other [CITY/AREA] homeowners find reliable
[SERVICE CATEGORY]. Would you mind taking 60 seconds to share your
experience?

[LARGE BUTTON: "Leave a Google Review"]

Thank you for supporting a local [CITY/AREA] business!

Best regards,
[OWNER NAME]
[BUSINESS NAME]
[PHONE]
```

**Implementation**:

- Send to all customers from the past 12 months who have NOT already been asked
- Segment by recency: customers from the last 30 days convert highest
- Send on Tuesday or Wednesday mornings (10am local time)
- Expected conversion rate: **5-10%** of recipients
- Do NOT email the same customer more than once for a review request

#### Channel 3: On-Site and Vehicle QR Codes (Passive Collection)

**Placement locations**:

- Service vehicles (rear window, side panels)
- Office reception/waiting area
- Invoices and receipts (printed)
- Business cards
- Job site leave-behind cards
- Branded yard signs (for contractors)

**QR code best practices**:

- Generate QR code that links directly to Google review form
- Include clear call-to-action text: "Scan to leave us a review!"
- Make QR code at least 1 inch x 1 inch for scanability
- Test the QR code on multiple devices before printing
- Use a branded short URL as backup for those who prefer typing

**Expected conversion**: 5-10% passive pickup rate. Lower conversion but zero
ongoing effort after initial setup.

#### Channel 4: Phone Call (High-Value Customers)

**When to use**: For jobs over $500 or customers who expressed strong satisfaction
during/after service.

**Call script**:

```
"Hi [FIRST NAME], this is [NAME] from [BUSINESS NAME]. I'm just calling to
follow up on the [SERVICE] we did [TIMEFRAME] ago. Is everything working
well? ... Great, I'm really glad to hear that.

I have a small favor to ask -- would you be willing to leave us a quick
Google review? It really helps other [CITY/AREA] homeowners find us, and
we'd appreciate it so much. I can send you the link by text right now if
that's convenient?"
```

**Implementation**:

- Call within 3-5 days of job completion
- Only call customers who rated the experience positively (NPS 9-10 if tracked)
- If they agree, immediately send the text link while on the phone
- Expected conversion rate: **40-60%** (highest of any channel)
- Time-intensive but extremely effective for building velocity quickly

#### Channel 5: Invoice/Receipt Integration (Systematic)

**Every single invoice and receipt** should include a review request. This is the
most systematic channel because it requires no additional effort after setup.

**Include on every invoice**:

- QR code linking to Google review form
- Short URL as text alternative
- Brief message: "We'd love your feedback! Scan the code or visit [URL]"
- Place at the bottom of the invoice, above or below payment total

---

### Platform Priority (Revised Weighting)

Not all review platforms are created equal. Allocate review generation effort
according to this priority:

| Platform                | Effort Allocation | Rationale                                |
|-------------------------|-------------------|------------------------------------------|
| Google Business Profile | 80%               | Primary local ranking factor             |
| Yelp                    | 10%               | High authority for service businesses    |
| HomeAdvisor/Angie's     | 5%                | Industry-specific trust signal           |
| Facebook                | 3%                | Social proof and brand trust             |
| Industry-Specific       | 2%                | Niche authority (Avvo, Healthgrades, etc)|

**Important Yelp note**: Never directly ask customers to leave a Yelp review (this
violates Yelp's terms and can trigger their filter). Instead, add Yelp to your
website's review page and let customers self-select. Focus direct asks on Google.

---

### 90-Day Review Acceleration Plan

| Phase     | Timeframe    | Actions                                              | Target         |
|-----------|-------------|------------------------------------------------------|----------------|
| Phase A   | Days 1-7    | Set up SMS automation, create email templates         | Infrastructure |
| Phase B   | Days 1-14   | Print QR codes, update invoices, vehicle signage      | Passive systems|
| Phase C   | Days 1-30   | Email blast to all customers from past 12 months      | 5-10 reviews   |
| Phase D   | Days 1-30   | Phone calls to top 20 highest-value customers         | 8-12 reviews   |
| Phase E   | Days 31-60  | SMS automation running on all new jobs                | 5-10 reviews   |
| Phase F   | Days 31-60  | Second email batch to non-responders (different list) | 3-5 reviews    |
| Phase G   | Days 61-90  | Ongoing SMS + passive QR collection                   | 5-10 reviews   |
| Phase H   | Ongoing     | Maintain 5-10 reviews/month velocity                  | Sustained      |

**90-day targets**:

- Aggressive: 25-35 new Google reviews
- Moderate: 15-25 new Google reviews
- Conservative: 10-15 new Google reviews

---

## Competitor Review Benchmarking

### Full Comparison Matrix

| Metric                          | Client    | Comp 1 | Comp 2 | Comp 3 | Comp 4 | Comp 5 |
|---------------------------------|-----------|--------|--------|--------|--------|--------|
| Total Google reviews            | [X]       | [X]    | [X]    | [X]    | [X]    | [X]    |
| Average rating                  | [X.X]     | [X.X]  | [X.X]  | [X.X]  | [X.X]  | [X.X]  |
| Reviews last 30 days            | [X]       | [X]    | [X]    | [X]    | [X]    | [X]    |
| Reviews last 90 days            | [X]       | [X]    | [X]    | [X]    | [X]    | [X]    |
| Monthly velocity (avg)          | [X.X]     | [X.X]  | [X.X]  | [X.X]  | [X.X]  | [X.X]  |
| Owner response rate             | [X]%      | [X]%   | [X]%   | [X]%   | [X]%   | [X]%   |
| Top service keywords in reviews | [list]    | [list] | [list] | [list] | [list] | [list] |
| Yelp reviews                    | [X]       | [X]    | [X]    | [X]    | [X]    | [X]    |
| Facebook reviews                | [X]       | [X]    | [X]    | [X]    | [X]    | [X]    |
| Total cross-platform            | [X]       | [X]    | [X]    | [X]    | [X]    | [X]    |

### Data Gathering Procedure

**Manual GBP checks** (always available):

1. Search for each competitor by name on Google
2. Click their GBP listing
3. Record: total reviews, average rating, most recent review date
4. Scroll through recent reviews to estimate monthly velocity
5. Note owner response patterns (responsive vs. silent)
6. Read 10-20 reviews to identify service keyword themes

**DFS MCP tools** (automated data pull):

Use `mcp__dfs-mcp__business_data_business_listings_search` to pull business listing
data including review metrics for each competitor:

```python
"""
DFS MCP Business Listings Search
Pull competitor review data via DataForSEO business listings API.
"""

# Example parameters for DFS MCP business listing search
search_params = {
    "keyword": "[SERVICE] [CITY]",  # e.g., "plumber Scottsdale"
    "location_name": "[CITY], [STATE], United States",
    "language_name": "English",
    "limit": 10,
}

# The API returns for each listing:
# - title (business name)
# - rating (average star rating)
# - reviews_count (total number of reviews)
# - url (GBP listing URL)
# - category (business category)
# - address (full address)
```

Use `mcp__dfs-mcp__serp_organic_live_advanced` to see how review data appears in
search results:

```python
"""
DFS MCP SERP Analysis
Check how review signals appear in organic search results.
"""

serp_params = {
    "keyword": "[BUSINESS NAME] [CITY] reviews",
    "location_name": "[CITY], [STATE], United States",
    "language_name": "English",
    "device": "mobile",
    "os": "android",
}

# Look for in results:
# - Review snippets in organic results
# - Star ratings displayed
# - Review count shown
# - Knowledge panel review data
```

---

## Review Sentiment Analysis Framework

### Theme Extraction Process

After collecting review text, categorize mentions into themes:

**Positive theme categories**:

| Theme Category     | Example Phrases                                          |
|--------------------|----------------------------------------------------------|
| Professionalism    | "professional", "courteous", "respectful", "uniformed"  |
| Timeliness         | "on time", "prompt", "fast", "same day", "quick"        |
| Quality of Work    | "excellent work", "thorough", "did a great job"         |
| Pricing            | "fair price", "reasonable", "good value", "competitive"  |
| Communication      | "explained everything", "kept us informed", "responsive" |
| Cleanliness        | "cleaned up", "left no mess", "tidy"                    |
| Expertise          | "knowledgeable", "experienced", "knew exactly"           |
| Customer Service   | "friendly", "helpful", "went above and beyond"           |

**Negative theme categories**:

| Theme Category     | Example Phrases                                          |
|--------------------|----------------------------------------------------------|
| Pricing Issues     | "overpriced", "hidden fees", "bait and switch"           |
| Timeliness Issues  | "late", "no show", "had to wait", "delayed"              |
| Quality Issues     | "had to come back", "didn't fix", "made it worse"        |
| Communication      | "couldn't reach", "never called back", "no updates"      |
| Professionalism    | "rude", "unprofessional", "messy", "disrespectful"       |
| Billing Issues     | "overcharged", "unexpected charges", "billing dispute"   |

### Competitive Sentiment Comparison

The most valuable insight from sentiment analysis is identifying what competitor
reviews praise that client reviews do NOT mention. These represent service
experience gaps that may be costing rankings and conversions.

**Analysis template**:

```
POSITIVE THEMES COMPARISON:

Theme               | Client Mentions | Competitor Avg Mentions | Gap
------------------  | --------------- | ----------------------- | ---
Professionalism     | [X]%            | [X]%                    | [+/-X]%
Timeliness          | [X]%            | [X]%                    | [+/-X]%
Quality of Work     | [X]%            | [X]%                    | [+/-X]%
Fair Pricing        | [X]%            | [X]%                    | [+/-X]%
Communication       | [X]%            | [X]%                    | [+/-X]%
Cleanliness         | [X]%            | [X]%                    | [+/-X]%

NEGATIVE THEMES:

Theme               | Client Mentions | Competitor Avg Mentions | Gap
------------------  | --------------- | ----------------------- | ---
Pricing Complaints  | [X]%            | [X]%                    | [+/-X]%
Late/No Show        | [X]%            | [X]%                    | [+/-X]%
Quality Complaints  | [X]%            | [X]%                    | [+/-X]%
Communication Issues| [X]%            | [X]%                    | [+/-X]%
```

---

## Scoring Rubric

### Review Health Score (100 Points Total)

```
REVIEW HEALTH SCORE CALCULATION:

============================================================
VOLUME (25 points):
------------------------------------------------------------
  0-4 reviews .......................... 0 points
  5-9 reviews .......................... 5 points
  10-19 reviews ........................ 10 points
  20-49 reviews ........................ 15 points
  50-99 reviews ........................ 20 points
  100+ reviews ......................... 25 points

============================================================
RATING (20 points):
------------------------------------------------------------
  Below 4.0 ............................ 0 points
  4.0-4.4 .............................. 5 points
  4.5-4.6 .............................. 10 points
  4.7-4.8 .............................. 15 points
  4.9-5.0 .............................. 20 points

============================================================
VELOCITY (20 points):
------------------------------------------------------------
  0 reviews/month ...................... 0 points
  1 review/month ....................... 5 points
  2-4 reviews/month .................... 10 points
  5-9 reviews/month .................... 15 points
  10+ reviews/month .................... 20 points

============================================================
RECENCY (15 points):
------------------------------------------------------------
  No reviews in 90 days ................ 0 points
  Reviews in last 90 days only ......... 5 points
  Reviews in last 30 days .............. 10 points
  5+ reviews in last 30 days ........... 15 points

============================================================
RESPONSE RATE (10 points):
------------------------------------------------------------
  0% responded ......................... 0 points
  1-49% responded ...................... 3 points
  50-89% responded ..................... 6 points
  90-99% responded ..................... 8 points
  100% responded ....................... 10 points

============================================================
KEYWORD RICHNESS (10 points):
------------------------------------------------------------
  No service/location keywords ......... 0 points
  Some keyword mentions ................ 5 points
  Frequent service + location keywords . 10 points

============================================================
```

### Score Interpretation

| Score Range | Classification | Priority Level | Action                            |
|-------------|---------------|----------------|-----------------------------------|
| 0-20        | Critical       | URGENT         | Review emergency -- all channels   |
| 21-40       | Poor           | HIGH           | Aggressive 90-day plan needed      |
| 41-60       | Below Average  | MEDIUM-HIGH    | Systematic generation required     |
| 61-75       | Average        | MEDIUM         | Optimize velocity and responses    |
| 76-85       | Good           | LOW-MEDIUM     | Fine-tune and maintain momentum    |
| 86-95       | Excellent      | LOW            | Maintain and monitor               |
| 96-100      | Elite          | MAINTENANCE    | Protect position, watch competitors|

---

## DFS MCP Data Sources

### Business Listing Data

The primary DFS MCP tool for review-related data is the business listings search.
This provides review counts and ratings for businesses matching a search query.

**Tool**: `mcp__dfs-mcp__business_data_business_listings_search`

**Usage**: Search for the client's business category + location to pull competitor
review metrics in bulk, rather than checking each competitor manually.

**Data returned includes**:

- Business name
- Average star rating
- Total review count
- Business category
- Address and location data
- Phone number
- Website URL

### SERP Review Signals

**Tool**: `mcp__dfs-mcp__serp_organic_live_advanced`

**Usage**: Search for the client's business name + "reviews" to see how review
signals appear in search results. This reveals:

- Whether review stars appear in organic search results
- Review snippet content shown in SERPs
- Review count displayed in knowledge panel
- Third-party review sites ranking for the business name + "reviews"

### Limitations

- DFS MCP does not provide individual review text (must be gathered manually
  or via GBP export)
- Review dates are not available through business listings search
- Velocity calculations require manual review counting or third-party tools
  like BrightLocal or Whitespark

---

## User Data Requests

Before beginning the audit, request the following from the client:

### Required

1. **Google Business Profile URL** -- the direct link to their GBP listing
2. **Top 5 competitor names** -- businesses they compete with most directly
3. **Target service keywords** -- the services they want to rank for
4. **Service area** -- cities and neighborhoods they serve

### Highly Recommended

5. **GBP review export** -- download from Google Takeout or GBP manager (includes
   all review text, ratings, dates, and reviewer names)
6. **Current review generation process** -- description of how they currently ask
   for reviews (if at all)
7. **Review response templates** -- any templates currently in use
8. **Customer list from last 12 months** -- for email/SMS review request campaigns

### Optional but Valuable

9. **Third-party review data** -- exports from Yelp, Facebook, HomeAdvisor, etc.
10. **Historical review tracking** -- data from BrightLocal, Whitespark, or similar
11. **NPS or customer satisfaction survey results** -- identifies happy customers
    most likely to leave positive reviews
12. **CRM access** -- for automated review request integration

---

## Output Format

The Review Signals Audit output should follow this structure when incorporated into
the full audit report:

```markdown
## Phase 3: Review Signals Audit

### Review Health Score: [XX]/100 -- [Classification]

### Current State Summary

| Metric                    | Value           | Benchmark       | Status     |
|---------------------------|-----------------|-----------------|------------|
| Total Google Reviews      | [X]             | [X] (comp avg)  | [emoji]    |
| Average Rating            | [X.X]           | 4.7+ target     | [emoji]    |
| Monthly Velocity          | [X.X]/month     | 5-10/month      | [emoji]    |
| Most Recent Review        | [Date]          | Within 7 days   | [emoji]    |
| Owner Response Rate       | [X]%            | 100% target     | [emoji]    |
| Service Keywords in Reviews| [X] of [Y]     | [Y] of [Y]      | [emoji]    |

### Competitor Benchmarking
[Full comparison matrix from Competitor Review Benchmarking section]

### Review Volume Gap Analysis
[Volume gap template filled in with actual data]

### Review Velocity Trend
[12-month velocity tracking table filled in with actual data]

### Sentiment Analysis
[Theme comparison tables filled in with actual data]

### Recommendations

#### Immediate Actions (Week 1)
1. [Specific action with expected impact]
2. [Specific action with expected impact]
3. [Specific action with expected impact]

#### Short-Term Actions (Days 8-30)
1. [Specific action with expected impact]
2. [Specific action with expected impact]
3. [Specific action with expected impact]

#### Medium-Term Actions (Days 31-90)
1. [Specific action with expected impact]
2. [Specific action with expected impact]

#### Ongoing Maintenance
1. [Recurring action with frequency]
2. [Recurring action with frequency]

### Review Generation Plan
[90-day acceleration plan table with specific targets]

### Response Templates
[Customized versions of the 4 response templates using client business data]

### Review KPIs to Track Monthly
- Total review count (Google)
- Average rating
- Monthly velocity (new reviews this month)
- Response rate
- Response time (average hours to respond)
- Service keyword mention rate in new reviews
```

---

## Cross-References

- **`/gbp-audit`** -- GBP completeness directly affects review visibility. An
  incomplete or unverified GBP listing suppresses review display and makes it
  harder for customers to find the review form. Always complete GBP optimization
  before investing heavily in review generation.

- **`/local-competitor-analysis`** -- Review benchmarking data feeds directly into
  the competitor analysis. The review comparison matrix should be shared between
  these two skills to avoid duplicate data collection.

- **`/local-citation-audit`** -- Review platform coverage overlaps with citation
  audit. Platforms like Yelp, BBB, and HomeAdvisor are both citation sources AND
  review platforms. Coordinate to ensure consistent NAP data across all review
  platforms.

- **`/local-seo-reporting`** -- Review KPIs (volume, rating, velocity, response
  rate) are PRIMARY success metrics in the monthly reporting dashboard. The
  scoring rubric from this skill should be calculated monthly and trended over
  time in the reporting skill output.

---

## Common Pitfalls to Avoid

1. **Never offer incentives for reviews** -- This violates Google's terms and can
   result in review removal or listing suspension. No discounts, no coupons, no
   contest entries in exchange for reviews.

2. **Never ask for "5-star reviews"** -- Ask for honest feedback. Specifying a
   star rating violates Google's guidelines and makes customers uncomfortable.

3. **Never gate reviews** -- Do not use a system that sends happy customers to
   Google and unhappy customers to a private feedback form. Google explicitly
   prohibits review gating.

4. **Never buy reviews** -- Purchased reviews from freelancers or review farms are
   detectable and will result in penalties, review removal, and potential listing
   suspension.

5. **Never respond emotionally to negative reviews** -- Always wait at least 1 hour
   before responding to a negative review. Emotional responses damage the brand
   more than the original negative review.

6. **Never ignore negative reviews** -- An unaddressed negative review signals to
   both Google and potential customers that the business does not care about
   customer satisfaction.

7. **Never batch-request reviews from employees or friends** -- Clusters of reviews
   from non-customers trigger Google's spam detection and can result in bulk
   review removal.

8. **Never stop generating reviews** -- Velocity matters more than volume. A
   business that stops asking for reviews will see ranking decay within 3-6 months
   even with a large existing review base.

---

## Appendix: Review Platform Direct Links

For generating review request URLs:

- **Google**: `https://search.google.com/local/writereview?placeid=[PLACE_ID]`
  - Find Place ID: https://developers.google.com/maps/documentation/places/web-service/place-id
- **Yelp**: `https://www.yelp.com/writeareview/biz/[BUSINESS_ALIAS]`
- **Facebook**: `https://www.facebook.com/[PAGE_NAME]/reviews/`
- **BBB**: Direct link from BBB business profile page

To find the Google Place ID programmatically, use the Google Places API or search
for the business name in the Google Place ID Finder tool.

---

*This skill is part of the Local SEO Auditor suite. Run `/review-audit` to execute
this assessment against a specific business.*
